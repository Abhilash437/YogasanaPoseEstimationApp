{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gtts\n",
      "  Using cached gTTS-2.3.2-py3-none-any.whl (28 kB)\n",
      "Collecting requests<3,>=2.27 (from gtts)\n",
      "  Obtaining dependency information for requests<3,>=2.27 from https://files.pythonhosted.org/packages/70/8e/0e2d847013cb52cd35b38c009bb167a1a26b2ce6cd6965bf26b47bc0bf44/requests-2.31.0-py3-none-any.whl.metadata\n",
      "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting click<8.2,>=7.1 (from gtts)\n",
      "  Obtaining dependency information for click<8.2,>=7.1 from https://files.pythonhosted.org/packages/00/2e/d53fa4befbf2cfa713304affc7ca780ce4fc1fd8710527771b58311a3229/click-8.1.7-py3-none-any.whl.metadata\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2.27->gtts)\n",
      "  Obtaining dependency information for charset-normalizer<4,>=2 from https://files.pythonhosted.org/packages/91/e6/8fa919fc84a106e9b04109de62bdf8526899e2754a64da66e1cd50ac1faa/charset_normalizer-3.2.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading charset_normalizer-3.2.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (31 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2.27->gtts)\n",
      "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.27->gtts)\n",
      "  Obtaining dependency information for urllib3<3,>=1.21.1 from https://files.pythonhosted.org/packages/9b/81/62fd61001fa4b9d0df6e31d47ff49cfa9de4af03adecf339c7bc30656b37/urllib3-2.0.4-py3-none-any.whl.metadata\n",
      "  Downloading urllib3-2.0.4-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2.27->gtts)\n",
      "  Obtaining dependency information for certifi>=2017.4.17 from https://files.pythonhosted.org/packages/4c/dd/2234eab22353ffc7d94e8d13177aaa050113286e93e7b40eae01fbf7c3d9/certifi-2023.7.22-py3-none-any.whl.metadata\n",
      "  Downloading certifi-2023.7.22-py3-none-any.whl.metadata (2.2 kB)\n",
      "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Downloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading charset_normalizer-3.2.0-cp311-cp311-macosx_11_0_arm64.whl (122 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.8/122.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading urllib3-2.0.4-py3-none-any.whl (123 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.9/123.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: urllib3, idna, click, charset-normalizer, certifi, requests, gtts\n",
      "Successfully installed certifi-2023.7.22 charset-normalizer-3.2.0 click-8.1.7 gtts-2.3.2 idna-3.4 requests-2.31.0 urllib3-2.0.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gtts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Body Keypoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/3j8BPdc.png\" style=\"height:300px\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "import os\n",
    "import pyttsx3\n",
    "from gtts import gTTS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle(a,b,c):\n",
    "    a = np.array(a) # First\n",
    "    b = np.array(b) # Mid\n",
    "    c = np.array(c) # End\n",
    "    \n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians*180.0/np.pi)\n",
    "    \n",
    "    if angle >180.0:\n",
    "        angle = 360-angle\n",
    "        \n",
    "    return angle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct Asana Angles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asana(path):\n",
    "     with mp_pose.Pose(min_detection_confidence = 0.5, min_tracking_confidence = 0.5) as pose:\n",
    "            img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "            image = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "            image.flags.writeable = False\n",
    "\n",
    "            results = pose.process(image)\n",
    "\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(img,cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            #mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "            #print(results.pose_landmarks)\n",
    "\n",
    "            try:\n",
    "                landmarks = results.pose_landmarks.landmark\n",
    "            except:\n",
    "                pass\n",
    "            right_shoulder = [landmarks[12].x, landmarks[12].y]\n",
    "            left_shoulder = [landmarks[11].x, landmarks[11].y]\n",
    "\n",
    "            right_elbow = [landmarks[14].x, landmarks[14].y]\n",
    "            right_wrist = [landmarks[16].x, landmarks[16].y]\n",
    "\n",
    "            left_elbow = [landmarks[13].x, landmarks[13].y]\n",
    "            left_wrist = [landmarks[15].x, landmarks[15].y]\n",
    "\n",
    "\n",
    "            right_hip = [landmarks[24].x, landmarks[24].y]\n",
    "            right_ankle = [landmarks[28].x, landmarks[28].y]\n",
    "            right_knee = [landmarks[26].x, landmarks[26].y]\n",
    "\n",
    "            left_hip = [landmarks[23].x, landmarks[23].y]\n",
    "            left_ankle = [landmarks[27].x, landmarks[27].y]\n",
    "            left_knee = [landmarks[25].x, landmarks[25].y]\n",
    "\n",
    "            right_shoulder = [landmarks[12].x, landmarks[12].y]\n",
    "            left_shoulder = [landmarks[11].x, landmarks[11].y]\n",
    "\n",
    "            Rightangle1 = calculate_angle(right_hip, right_knee, right_ankle)\n",
    "            Rightangle2 = calculate_angle(right_knee, right_hip, right_shoulder)\n",
    "            Rightangle3 = calculate_angle(right_shoulder, right_elbow, right_wrist)\n",
    "            Rightangle4 = calculate_angle(right_elbow, right_shoulder, right_hip)\n",
    "\n",
    "            Leftangle1 = calculate_angle(left_hip, left_knee, left_ankle)\n",
    "            Leftangle2 = calculate_angle(left_knee, left_hip, left_shoulder)\n",
    "            Leftangle3 = calculate_angle(left_shoulder, left_elbow, left_wrist)\n",
    "            Leftangle4 = calculate_angle(left_elbow, left_shoulder, left_hip)\n",
    "\n",
    "            asana = {\n",
    "                #  'name': 'updogPose',\n",
    "                 'r1':Rightangle1,\n",
    "                 'r2':Rightangle2,\n",
    "                 'r3':Rightangle3,\n",
    "                 'r4':Rightangle4,\n",
    "                 'l1':Leftangle1,\n",
    "                 'l2':Leftangle2,\n",
    "                 'l3':Leftangle3,\n",
    "                 'l4':Leftangle4,\n",
    "            }\n",
    "            #print(updogPose)\n",
    "            return asana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'r1': 29.38046240491125,\n",
       " 'r2': 134.51534604539273,\n",
       " 'r3': 147.4238422339296,\n",
       " 'r4': 172.84410456105823,\n",
       " 'l1': 179.16629470430553,\n",
       " 'l2': 178.89667287483715,\n",
       " 'l3': 149.36240094358772,\n",
       " 'l4': 179.45510922285433}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v=asana(\"Tree-Pose-–-Vrikshasana.jpg\")\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'r1': 178.89854881212344,\n",
       " 'r2': 176.01575783024214,\n",
       " 'r3': 163.72833764900446,\n",
       " 'r4': 177.33857672741502,\n",
       " 'l1': 177.25088126469652,\n",
       " 'l2': 179.8089948884223,\n",
       " 'l3': 160.5813420246325,\n",
       " 'l4': 179.7820327675253}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t=asana(\"Tadasana_2280.jpg.webp\")\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'r1': 168.32119845759485,\n",
       " 'r2': 108.43561170056006,\n",
       " 'r3': 165.77756334111854,\n",
       " 'r4': 14.620296070962176,\n",
       " 'l1': 165.60809726785547,\n",
       " 'l2': 112.20673496913787,\n",
       " 'l3': 165.5910057247301,\n",
       " 'l4': 14.410799597028227}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=asana(\"images-2.jpeg\")\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:\n",
    "1. Tadasana:\n",
    "    a.join your hands together by interlocking your fingers. palms facing upwards. stand straight\n",
    "    b.raise your hands\n",
    "    c.stretch arms and feet\n",
    "2. Vrikshasana\n",
    "    a.Stand tall and straight with arms by the side of your body.\n",
    "    b.Bend your right knee and place the right foot high up on your left thigh. The sole of the foot should be placed flat and firmly near the root of the thigh.\n",
    "    c.Make sure that your left leg is straight. Find your balance.\n",
    "    c.Once you are well balanced, take a deep breath in, gracefully raise your arms over your head from the side, and bring your palms together in ‘Namaste’ mudra (hands-folded position). \n",
    "3. Bhujangasana\n",
    "    a.lie down\n",
    "    b.push your torso up using your hands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General Instructions: \n",
    "1. Make boolean variables for each step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tadasana:\n",
    "1. stand straight: legs and body straight (r1,r2,l1,l2)\n",
    "2. stretch arms: r3,l3,r2,l2 raise arms using y coordinates. refer dumbell curl video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vrikshana:\n",
    "1. stand straight: r1,r2,l1,l2\n",
    "2. bending right knee: r1, l1 also\n",
    "3. raise arms: r3,l3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bhujangasana:\n",
    "1. r1,r2,r3, l1,l2,l3\n",
    "2. r3, r2, l3,l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **<font style=\"color:rgb(134,245,304)\">Verify</font>**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import mediapipe as mp\n",
    "# import os\n",
    "# import matplotlib.pyplot as plt\n",
    "# # Initialize MediaPipe Pose model\n",
    "# mp_pose = mp.solutions.pose\n",
    "# pose = mp_pose.Pose()\n",
    "\n",
    "# # Initialize MediaPipe Drawing Utils\n",
    "# mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# image_path='Tadasana_2280.jpg.webp'\n",
    "# ls=image_path.split('\\\\')\n",
    "# image_path = '/'.join(map(str, ls))\n",
    "\n",
    "\n",
    "# # Read the image\n",
    "# image = cv2.imread(image_path)\n",
    "# image_height, image_width, _ = image.shape\n",
    "\n",
    "# # Convert the BGR image to RGB for MediaPipe\n",
    "# image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# # Process the image and get the pose landmarks\n",
    "# results = pose.process(image_rgb)\n",
    "\n",
    "# # Draw the pose landmarks on the image\n",
    "# if results.pose_landmarks:\n",
    "#     mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "# # Display the result\n",
    "# plt.imshow(image)\n",
    "\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "# plt.show()\n",
    "# user_pose=tadasana(image_path)\n",
    "# tad_eval(user_pose)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **<font style=\"color:rgb(134,190,348)\">Logic</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tadasana:\n",
    "1. stand straight: legs and body straight (r1,r2,l1,l2)\n",
    "2. raise arms using y coordinates. refer dumbell curl video\n",
    "3. stretch arms: r3,l3,r2,l2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "at every time step:\n",
    "1. Maintain int variable for current step (curr)\n",
    "2. maintain bool variable for each step (s1,s2,s3)\n",
    "3. for each frame: calc boolean values from t=1 till t=curr\n",
    "for tadasana:\n",
    "curr=1 (global)\n",
    "\n",
    "if(curr==1):\n",
    "    s1=t1()\n",
    "    if(s1):\n",
    "        curr=2\n",
    "\n",
    "elif (curr==2):\n",
    "    s1=t1()\n",
    "    s2=ts()\n",
    "    if(s1 and s2):\n",
    "        curr=3\n",
    "    elif(not s1):\n",
    "        curr=1\n",
    "   \n",
    "else:\n",
    "    s1=t1()\n",
    "    s2=t2()\n",
    "    s3=t3()\n",
    "    if(s1 and s2 and s3):\n",
    "        pass #end condition for step (congrats, terminate)\n",
    "    elif(not s1):\n",
    "        curr=1\n",
    "    elif(not s2):\n",
    "       curr=2\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_step=1\n",
    "asana='t' #to be recognised or given\n",
    "feedback=\"\"\n",
    "counter = 0\n",
    "final=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedbacks = {\n",
    "    'tadasana':{\n",
    "        1: {\n",
    "            'Good': 'Good Job, moving to step 2',\n",
    "            'Bad': 'Please stand upright with your legs and body straight'\n",
    "        },\n",
    "        2: {\n",
    "            'Good': 'Congratulations, moving to step 3',\n",
    "            'Bad': 'Please lock your palms, with them facing the ground. Then slowly raise your arms'\n",
    "        },\n",
    "        3 : {\n",
    "            'Good': 'Congratulations, you have completed the asana',\n",
    "            'Bad': 'Please stretch your arms'\n",
    "        }\n",
    "    },\n",
    "    'vrikshasana': {\n",
    "        1: {\n",
    "            'Good': 'Good Job, moving to step 2',\n",
    "            'Bad': 'Please stand up with your legs and body straight'\n",
    "        },\n",
    "        2: {\n",
    "            'Good': 'Congratulations, moving to step 3',\n",
    "            'Bad': 'Please lift your right leg slowly and place the right feet against your left thigh'\n",
    "        },\n",
    "        3 : {\n",
    "            'Good': 'Congratulations, you have completed the asana',\n",
    "            'Bad': 'Slowly raise your arms, and stretch your arms'\n",
    "        }\n",
    "    },\n",
    "    'bhujangasana': {\n",
    "        1: {\n",
    "            'Good': 'Good Job, moving to step 2',\n",
    "            'Bad': 'Lie down on your stomach straight with your palms facing up'\n",
    "        },\n",
    "        2: {\n",
    "            'Good': 'Congratulations, moving to step 3',\n",
    "            'Bad': 'Slowly move your arms towards your chest with palms on the ground'\n",
    "        },\n",
    "        3 : {\n",
    "            'Good': 'Congratulations, you have completed the asana',\n",
    "            'Bad': 'Lift yourself up by stretching your arms slowly until your arms are completely straight, and hold for 10 seconds'\n",
    "        }\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify Asanas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tad_eval(user_pose):\n",
    "    #compare with original\n",
    "    diff={}\n",
    "    for x in user_pose:\n",
    "        diff[x]=abs(user_pose[x]-t[x])\n",
    "    # print(diff)\n",
    "    return (diff)\n",
    "    #make a funcion for each step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vrik_eval(user_pose):\n",
    "    #compare with original\n",
    "    diff={}\n",
    "    for x in user_pose:\n",
    "        diff[x]=abs(user_pose[x]-v[x])\n",
    "    # print(diff)\n",
    "    return (diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_1(diff):\n",
    "    all=True\n",
    "    angles=['r1','r2','l1','l2']\n",
    "    for angle in angles:\n",
    "        if(diff[angle]>5):\n",
    "            all=False\n",
    "    if(all):    \n",
    "        return [feedbacks['tadasana'][1]['Good'],True]\n",
    "    else:\n",
    "        return [feedbacks['tadasana'][1]['Bad'],False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_2(coordinates):\n",
    "    cond=((coordinates['left_shoulder']>=coordinates['left_elbow'])and (coordinates['right_shoulder']>=coordinates['right_elbow']))\n",
    "    if(cond):\n",
    "        return [feedbacks['tadasana'][2]['Good'], True]\n",
    "    else:\n",
    "        return [feedbacks['tadasana'][2]['Bad'],False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_3(diff):\n",
    "    all=True\n",
    "    angles=['r3','l3','r4','l4']\n",
    "    for angle in angles:\n",
    "        if(diff[angle]>10):\n",
    "            all=False\n",
    "    if(all):\n",
    "        return [feedbacks['tadasana'][3]['Good'], True]\n",
    "    else:\n",
    "        return [feedbacks['tadasana'][3]['Bad'], False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def v_1(diff): #For Vrikshanana Right Leg\n",
    "    all=True\n",
    "    angles=['l1','l2']\n",
    "    for angle in angles:\n",
    "        if(diff[angle]>5):\n",
    "            all=False\n",
    "    if(all):    \n",
    "        return [feedbacks['vrikshasana'][1]['Good'],True]\n",
    "    else:\n",
    "        return [feedbacks['vrikshasana'][1]['Bad'],False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def v_2(diff):\n",
    "    #cond=((coordinates['left_shoulder']>=coordinates['left_elbow'])and (coordinates['right_shoulder']>=coordinates['right_elbow']))\n",
    "    \n",
    "    if(diff['r2']<=20):\n",
    "        return [feedbacks['vrikshasana'][2]['Good'], True]\n",
    "    else:\n",
    "        return [feedbacks['vrikshasana'][2]['Bad'],False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def v_3(diff):\n",
    "    all=True\n",
    "    angles=['r3','l3','r4','l4']\n",
    "    for angle in angles:\n",
    "        if(diff[angle]>30):\n",
    "            all=False\n",
    "    if(all):\n",
    "        return [feedbacks['vrikshasana'][3]['Good'], True]\n",
    "    else:\n",
    "        return [feedbacks['vrikshasana'][3]['Bad'], False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "## Setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Recolor image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Extract landmarks\n",
    "        try:\n",
    "            \n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            right_shoulder = [landmarks[12].x, landmarks[12].y]\n",
    "            left_shoulder = [landmarks[11].x, landmarks[11].y]\n",
    "\n",
    "            right_elbow = [landmarks[14].x, landmarks[14].y]\n",
    "            right_wrist = [landmarks[16].x, landmarks[16].y]\n",
    "\n",
    "            left_elbow = [landmarks[13].x, landmarks[13].y]\n",
    "            left_wrist = [landmarks[15].x, landmarks[15].y]\n",
    "\n",
    "\n",
    "            right_hip = [landmarks[24].x, landmarks[24].y]\n",
    "            right_ankle = [landmarks[28].x, landmarks[28].y]\n",
    "            right_knee = [landmarks[26].x, landmarks[26].y]\n",
    "\n",
    "            left_hip = [landmarks[23].x, landmarks[23].y]\n",
    "            left_ankle = [landmarks[27].x, landmarks[27].y]\n",
    "            left_knee = [landmarks[25].x, landmarks[25].y]\n",
    "\n",
    "            right_shoulder = [landmarks[12].x, landmarks[12].y]\n",
    "            left_shoulder = [landmarks[11].x, landmarks[11].y]\n",
    "            #calculate angles: \n",
    "            Rightangle1 = calculate_angle(right_hip, right_knee, right_ankle)\n",
    "            Rightangle2 = calculate_angle(right_knee, right_hip, right_shoulder)\n",
    "            Rightangle3 = calculate_angle(right_shoulder, right_elbow, right_wrist)\n",
    "            Rightangle4 = calculate_angle(right_elbow, right_shoulder, right_hip)\n",
    "\n",
    "            Leftangle1 = calculate_angle(left_hip, left_knee, left_ankle)\n",
    "            Leftangle2 = calculate_angle(left_knee, left_hip, left_shoulder)\n",
    "            Leftangle3 = calculate_angle(left_shoulder, left_elbow, left_wrist)\n",
    "            Leftangle4 = calculate_angle(left_elbow, left_shoulder, left_hip)\n",
    "            \n",
    "            cv2.putText(image,\\\n",
    "                        str(Leftangle3), \\\n",
    "                            tuple(np.multiply([left_elbow[0], left_elbow[1]], [640,480]).astype(int)),\\\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255),2,cv2.LINE_AA)\n",
    "         \n",
    "            user={\n",
    "                #  'name': 'updogPose',\n",
    "                 'r1':Rightangle1,\n",
    "                 'r2':Rightangle2,\n",
    "                 'r3':Rightangle3,\n",
    "                 'r4':Rightangle4,\n",
    "                 'l1':Leftangle1,\n",
    "                 'l2':Leftangle2,\n",
    "                 'l3':Leftangle3,\n",
    "                 'l4':Leftangle4,\n",
    "            }\n",
    "            # print(user)\n",
    "            \n",
    "            # print(diff)\n",
    "            coordinates={\n",
    "                'left_shoulder':left_shoulder[1],\n",
    "                'right_shoulder':right_shoulder[1],\n",
    "                'left_elbow':left_elbow[1],\n",
    "                'right_elbow':right_elbow[1]\n",
    "            }\n",
    "\n",
    "            if(asana=='t'):\n",
    "                diff=tad_eval(user)\n",
    "                if(curr_step==1):\n",
    "                    # print(\"in step 1\")\n",
    "                    s1=t_1(diff)\n",
    "                    # print(s1)\n",
    "                    if(s1[1]):\n",
    "                        curr_step=2\n",
    "                        feedback=s1[0]\n",
    "                    else:\n",
    "                        feedback=s1[0]\n",
    "                elif (curr_step==2):\n",
    "                    # print(\"in step 2\")\n",
    "\n",
    "                    s1=t_1(diff)\n",
    "                    s2=t_2(coordinates)\n",
    "                    if(s1[1] and s2[1]):\n",
    "                        curr_step=3\n",
    "                        feedback=s2[0]\n",
    "                    elif(not s1[1]):\n",
    "                        curr_step=1\n",
    "                        feedback=s1[0]\n",
    "                    elif(not s2[1]):\n",
    "                        curr_step = 2\n",
    "                        feedback = s2[0]\n",
    "                elif(curr_step==3):\n",
    "                    # print(\"in step 3\")\n",
    "\n",
    "                    s1=t_1(diff)\n",
    "                    s2=t_2(coordinates)\n",
    "                    s3=t_3(diff)\n",
    "                    if(s1[1] and s2[1] and s3[1]):\n",
    "                        feedback='congratulations!'\n",
    "                        curr_step=4 \n",
    "                    elif(not s1[1]):\n",
    "                        curr_step=1\n",
    "                        feedback=s1[0]\n",
    "                    elif(not s2[1]):\n",
    "                        curr_step=2\n",
    "                        feedback=s2[0]\n",
    "                    elif(not s3[1]):\n",
    "                        curr_step=3\n",
    "                        feedback=s3[0]\n",
    "                elif(curr_step==4):\n",
    "                    \n",
    "                    if(counter<50):\n",
    "                        counter += 1\n",
    "                        print(counter)\n",
    "                    if(counter==50):\n",
    "                        cap.release()\n",
    "                        cv2.destroyAllWindows()\n",
    "            elif asana == 'v':\n",
    "                diff=vrik_eval(user)\n",
    "                if(curr_step==1):\n",
    "                    # print(\"in step 1\")\n",
    "                    s1=v_1(diff)\n",
    "                    # print(s1)\n",
    "                    if(s1[1]):\n",
    "                        curr_step=2\n",
    "                        feedback=s1[0]\n",
    "                    else:\n",
    "                        feedback=s1[0]\n",
    "                elif (curr_step==2):\n",
    "                    # print(\"in step 2\")\n",
    "\n",
    "                    s1=v_1(diff)\n",
    "                    s2=v_2(diff)\n",
    "                    if(s1[1] and s2[1]):\n",
    "                        curr_step=3\n",
    "                        feedback=s2[0]\n",
    "                    elif(not s1[1]):\n",
    "                        curr_step=1\n",
    "                        feedback=s1[0]\n",
    "                    elif(not s2[1]):\n",
    "                        curr_step = 2\n",
    "                        feedback = s2[0]\n",
    "                elif(curr_step==3):\n",
    "                    # print(\"in step 3\")\n",
    "\n",
    "                    s1=v_1(diff)\n",
    "                    s2=v_2(diff)\n",
    "                    s3=v_3(diff)\n",
    "                    if(s1[1] and s2[1] and s3[1]):\n",
    "                        feedback='congratulations!'\n",
    "                        curr_step=4 \n",
    "                    elif(not s1[1]):\n",
    "                        curr_step=1\n",
    "                        feedback=s1[0]\n",
    "                    elif(not s2[1]):\n",
    "                        curr_step=2\n",
    "                        feedback=s2[0]\n",
    "                    elif(not s3[1]):\n",
    "                        curr_step=3\n",
    "                        feedback=s3[0]\n",
    "                elif(curr_step==4):\n",
    "                    final=True\n",
    "                    if(counter<50):\n",
    "                        counter += 1\n",
    "                        print(counter)\n",
    "                    if(counter==50):\n",
    "                        cap.release()\n",
    "                        cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "            cv2.rectangle(image, (0,0), (525,73), (245,117,16), -1)\n",
    "\n",
    "            cv2.putText(image, feedback, (15,12), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 1, cv2.LINE_AA)\n",
    "            tts=gTTS(feedback)\n",
    "            tts.save(\"output.mp3\")\n",
    "            if(not final):\n",
    "                os.system(\"afplay output.mp3\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "                    \n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)  \n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"afplay output.mp3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add:\n",
    "1. Beginner and Intermediate\n",
    "2. Add co-evolutionary learning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
